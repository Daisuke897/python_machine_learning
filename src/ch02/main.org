分類問題 単純な機械学習アルゴリズムの訓練
* 取り上げる内容
** 機械学習のアルゴリズムを理解する
** pandas, NumPy, matplotlibを使ってデータの読み込み、処理、可視化を行う
** 線形分類のアルゴリズムをPythonで実装する
* パーセプトロンの学習アルゴリズムをPythonで実装する
#+begin_src emacs-lisp
  (pyvenv-activate "~/project/python_machine_learning")
#+end_src

#+RESULTS:

** オブジェクト指向のパーセプトロンAPI
#+begin_src python :session
  import numpy as np

  class Perception(object):
      """パーセプトロンの分類器"""

      def __init__(self, eta=0.01, n_iter=50, random_state=1):
          self.eta = eta
          self.n_iter = n_iter
          self.random_state = random_state

      def fit(self, X, y):
          """訓練データに適合させる"""
          rgen = np.random.RandomState(self.random_state)
          # 正規分布に従う乱数を生成
          # locは平均、scaleは標準偏差である。
          self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])
          self.errors_ = []

          for _ in range(self.n_iter):
              errors = 0
              for xi, target in zip(X, y):
                  update = self.eta * (target - self.predict(xi))
                  self.w_[1:] += update * xi
                  self.w_[0] += update
                  errors += int(update != 0.0)
              self.errors_.append(errors)
          return self

      def net_input(self, X):
          """Calculate net input"""
          return np.dot(X, self.w_[1:]) + self.w_[0]

      def predict(self, X):
          """Return class label after unit step"""
          return np.where(self.net_input(X) >= 0.0, 1, -1)
#+end_src

#+RESULTS:

#+begin_src python :session
  v1 = np.array([1, 2, 3])
  v2 = 0.5 * v1
  np.arccos(v1.dot(v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))
#+end_src

#+RESULTS:
: 0.0

#+begin_src python :session
  import pandas as pd

  s = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'

  df = pd.read_csv(s, header=None, encoding="utf-8")

  df.tail()
#+end_src

#+RESULTS:
:        0    1    2    3               4
: 145  6.7  3.0  5.2  2.3  Iris-virginica
: 146  6.3  2.5  5.0  1.9  Iris-virginica
: 147  6.5  3.0  5.2  2.0  Iris-virginica
: 148  6.2  3.4  5.4  2.3  Iris-virginica
: 149  5.9  3.0  5.1  1.8  Iris-virginica

Iris-setosaの50枚の花とIris-versicolorの50枚の花に対応する先頭の100個のクラスレベルを抽出する
#+begin_src python :session
  # 1-100行目の目的変数を抽出
  y = df.iloc[0:100, 4].values
  # Iris-setosaを-1, Iris-versicolorを1に変換
  y = np.where(y == "Iris-setosa", -1, 1)
  # 1-100行目の1, 3列目を抽出
  X = df.iloc[0:100, [0, 2]].values
#+end_src

#+RESULTS:

#+begin_src python :session :results file link
  import matplotlib.pyplot as plt

  plt.close('all')

  plt.scatter(X[:50, 0], X[:50, 1],
              color="red", marker='o', label="setosa")
  plt.scatter(X[50:100, 0], X[50:100, 1],
              color="blue", marker='x', label="versicolor")

  plt.xlabel("sepal length [cm]")
  plt.ylabel("pepal length [cm]")
  plt.legend(loc="upper left")

  fname = "images/02_06.png"
  plt.savefig(fname)
  fname
#+end_src

#+RESULTS:
[[file:images/02_06.png]]

#+begin_src python :session :results file link
  plt.close('all')

  ppn = Perception(eta=0.1, n_iter=10)

  ppn.fit(X, y)

  plt.plot(range(1, len(ppn.errors_) + 1), ppn.errors_, marker='o')
  plt.xlabel('Epochs')
  plt.ylabel('Number of updates')

  fname = 'images/02_07.png'

  plt.savefig('images/02_07.png')

  fname
#+end_src

#+RESULTS:
[[file:images/02_07.png]]

2次元のデータセットの決定境界を可視化したい

#+begin_src python :session :results file link
  from matplotlib.colors import ListedColormap

  plt.close('all')

  def plot_decision_regions(X, y, classifier, resolution = 0.02):

      # マーカーとカラーマップの準備
      markers = ('s', 'x', 'o', '^', 'v')
      colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')
      cmap = ListedColormap(colors[:len(np.unique(y))])

      # 決定領域のプロット
      x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1
      x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1
      # グリッドポイントの生成
      xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),
                             np.arange(x2_min, x2_max, resolution))
      # 各特徴量を1次元配列に変換して予測を実行
      Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)
      Z = Z.reshape(xx1.shape)
      plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)
      plt.xlim(xx1.min(), xx1.max())
      plt.ylim(xx2.min(), xx2.max())

      # クラスごとに訓練データをプロット
      for idx, cl in enumerate(np.unique(y)):
          plt.scatter(x=X[y == cl, 0],
                      y=X[y == cl, 1],
                      alpha=0.8,
                      c=colors[idx],
                      marker=markers[idx],
                      label=cl,
                      edgecolor="black")

  plot_decision_regions(X, y, classifier=ppn)
  plt.xlabel("sepal length [cm]")
  plt.ylabel("pepal length [cm]")

  plt.legend(loc="upper left")

  fname = "images/02_08.png"

  plt.savefig(fname)

  fname
#+end_src

#+RESULTS:
[[file:images/02_08.png]]

** ADALINEをPythonで実装する

#+begin_src python :session
  import numpy as np


  class AdalineGD(object):
      """ADAptive LInear NEuron classifier."""

      def __init__(self, eta=0.01, n_iter=50, random_state=1):
          self.eta = eta
          self.n_iter = n_iter
          self.random_state = random_state

      def fit(self, X, y):
          """訓練データに適合させる"""
          rgen = np.random.RandomState(self.random_state)
          # 正規分布に従う乱数を生成
          # locは平均、scaleは標準偏差である。
          self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])
          self.cost_ = []

          for i in range(self.n_iter):
              net_input = self.net_input(X)

              output = self.activation(net_input)
              errors = (y - output)
              self.w_[1:] += self.eta * X.T.dot(errors)
              self.w_[0] += self.eta * errors.sum()
              cost = (errors**2).sum() / 2.0
              self.cost_.append(cost)

          return self

      def net_input(self, X):
          """Calculate net input"""
          return np.dot(X, self.w_[1:]) + self.w_[0]

      def activation(self, X):
          """Compute linear activation"""
          return X

      def predict(self, X):
          """Return class label after unit step"""
          return np.where(self.activation(self.net_input(X)) >= 0.0, 1, -1)
#+end_src

#+RESULTS:

#+begin_src python :session :results file link
  plt.close('all')
  # 描画領域を1行2列に分割
  fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))

  ada1 = AdalineGD(n_iter=10, eta=0.01).fit(X, y)
  ax[0].plot(range(1, len(ada1.cost_) + 1), np.log10(ada1.cost_), marker='o')
  ax[0].set_xlabel('Epochs')
  ax[0].set_ylabel('log(Sum-squared-error)')
  ax[0].set_title('Adaline - Learning rate 0.01')

  ada2 = AdalineGD(n_iter=10, eta=0.0001).fit(X, y)
  ax[1].plot(range(1, len(ada2.cost_) + 1), ada2.cost_, marker='o')
  ax[1].set_xlabel('Epochs')
  ax[1].set_ylabel('Sum-squared-error')
  ax[1].set_title('Adaline - Learning rate 0.0001')

  fname = "images/02_11.png"

  plt.savefig(fname)

  fname
#+end_src

#+RESULTS:
[[file:images/02_11.png]]

** 特徴量のスケーリングを通じて勾配降下法を改善する
標準化というスケーリング手法を用いる
データセットに標準正規分布のゼロ平均と単位分散という特性が与えられる
平均をずらして中心が0になるようにする。
$x_{j}^{\prime} = \frac{x_{j} - \mu_{j}}{\sigma_{j}}$

標準化の実現
#+begin_src python :session
  X_std = np.copy(X)

  X_std[:, 0] = (X[:, 0] - X[:, 0].mean()) / X[:, 0].std()
  X_std[:, 1] = (X[:, 1] - X[:, 1].mean()) / X[:, 1].std()
#+end_src

#+RESULTS:

標準化後は、学習率0.01と小さなエポック数に基づいてADALINEを再び訓練し、収束することを確認する

#+begin_src python :session :results file link
  plt.close('all')

  ada_gd = AdalineGD(n_iter=15, eta=0.01)
  ada_gd.fit(X_std, y)

  plot_decision_regions(X_std, y, classifier=ada_gd)
  plt.title('Adaline - Gradient Descent')
  plt.xlabel('sepal length [standardized]')
  plt.ylabel('petal length [standardized]')
  plt.legend(loc='upper left')
  plt.tight_layout()

  fname = "images/02_14_1.png"

  plt.savefig(fname)

  fname
#+end_src

#+RESULTS:
[[file:images/02_14_1.png]]

#+begin_src python :session :results file link
  plt.close('all')

  plt.plot(range(1, len(ada_gd.cost_) + 1), ada_gd.cost_, marker='o')
  plt.xlabel('Epochs')
  plt.ylabel('Sum-squared-error')

  plt.tight_layout()

  fname = "images/02_14_2.png"

  plt.savefig(fname)

  fname
#+end_src

#+RESULTS:
[[file:images/02_14_2.png]]

** 確率的勾配降下法
訓練データごとに段階的に重みを更新する

#+begin_src python :session
  from numpy.random import seed

  class AdalineSGD(object):
      """ADAptive LInear NEuron classifier."""

      def __init__(self, eta=0.01, n_iter=10, shuffle=True, random_state=None):
          self.eta = eta
          self.n_iter = n_iter
          self.w_initialized = False
          self.shuffle = shuffle
          self.random_state = random_state

      def fit(self, X, y):
          """ Fit training data. """

          self._initialize_weights(X.shape[1])
          self.cost_ = []

          for i in range(self.n_iter):
              if self.shuffle:
                  X, y = self._shuffle(X, y)
              cost = []
              for xi, target in zip(X, y):
                  cost.append(self._update_weights(xi, target))
              ave_cost = sum(cost) / len(y)
              self.cost_.append(avg_cost)

          return self

      def partial_fit(self, X, y):
          """Fit training data without reinitializing the weights"""
          if not self.w_initialized:
              self._initialize_weights(X.shape[1])
          if y.ravel().shape[0] > 1:
              for xi, target in zip(X, y):
                  self._update_weights(xi, target)
          else:
              self._update_weights(X, y)

          return self

      def _shuffle(self, X, y):
          """Shuffle training data"""
          r = self.rgen.permutation(len(y))
          return X[r], y[r]

      def _initialize_weights(self, m):
          """Initialize weights to small random numbers"""
          self.rgen = np.random.RandomState(self.random_state)
          self.w_ = self.rgen.normal(loc=0.0, scale=0.01, size=1 + m)
          self.w_initialized = True

      def _update_weights(self, xi, target):
          """Apply Adaline learning rule to update the weights"""
          output = self.activation(self.net_input(xi))
          error = (target - output)
          self.w_[1:] += self.eta * xi.dot(error)
          self.w_[0] += self.eta * error
          cost = 0.5 * error**2
          return cost
#+end_src

#+RESULTS:
