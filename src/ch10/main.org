*回帰分析 ―連続値をとる目的変数の予測*

#+begin_src emacs-lisp
  (pyvenv-activate "~/project/python_machine_learning")
#+end_src

#+RESULTS:
* 線形回帰
* Housingデータセットの探索
** Housingデータセットをデータフレームに読み込む
目的変数として住宅価格の中央値（MEDV）を使う
#+begin_src python :session :results value
  import pandas as pd

  df = pd.read_csv("https://raw.githubusercontent.com/rasbt/"
                   "python-machine-learning-book-3rd-edition/"
                   "master/ch10/housing.data.txt",
                   header=None,
                   sep="\s+")

  df.columns = ["CRIM", "ZN", "INDUS", "CHAS",
                "NOX", "RM", "AGE", "DIS", "RAD",
                "TAX", "PTRATIO", "B", "LSTAT", "MEDV"]

  df.head(5)
#+end_src

#+RESULTS:
:       CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  PTRATIO       B  LSTAT  MEDV
: 0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0     15.3  396.90   4.98  24.0
: 1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0     17.8  396.90   9.14  21.6
: 2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0     17.8  392.83   4.03  34.7
: 3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0     18.7  394.63   2.94  33.4
: 4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0     18.7  396.90   5.33  36.2
** データセットの重要な特性を可視化する
*探索的データ解析* 機械学習モデルを訓練する前の最初の重要なステップとして推奨
*散布図行列* を作成する

#+begin_src python :session :results file link
  import matplotlib.pyplot as plt
  from mlxtend.plotting import scatterplotmatrix
  cols = ["LSTAT", "INDUS", "NOX", "RM", "MEDV"]
  plt.close("all")
  scatterplotmatrix(df[cols].values, figsize=(10, 8), names = cols, alpha = 0.5)
  plt.tight_layout()

  fname = "images/10_03.png"
  plt.savefig(fname)
  fname
#+end_src

#+RESULTS:
[[file:images/10_03.png]]
** 相関行列を使って関係を調べる

#+begin_src python :session :results file link
  from mlxtend.plotting import heatmap
  import numpy as np
  plt.close("all")
  cm = np.corrcoef(df[cols].values.T) # ピアソンの積率相関係数を計算
  hm = heatmap(cm, row_names = cols, column_names = cols)
  fname = "images/10_04.png"
  plt.savefig(fname)
  fname
#+end_src

#+RESULTS:
[[file:images/10_04.png]]

* 最小二乗線形回帰モデルの実装

** 勾配降下法を使って回帰パラメータの回帰を解く

#+begin_src python :session
  # 基本的な線形回帰モデル
  class LinearRegressionGD(object):

      # 初期化を実行する__init__
      def __init__(self, eta=0.001, n_iter = 20):
          self.eta = eta          # 学習率
          self.n_iter = n_iter    # 訓練回数

      # 訓練を実行するfit
      def fit(self, X, y):
          self.w_ = np.zeros(1 + X.shape[1]) # 重みを初期化
          self.cost_ = []                    # コスト関数の値を初期化
          for i in range(self.n_iter):
              output = self.net_input(X) # 活性化関数の出力を計算
              errors = (y - output)      # 誤差を計算
              self.w_[1:] += self.eta * X.T.dot(errors) # 重みw_{1}以降を更新
              self.w_[0] += self.eta * errors.sum()     # 重みw_{0}を更新
              cost = (errors ** 2).sum() / 2.0          # コスト関数を計算
              self.cost_.append(cost)                   # コスト関数の値を格納
          return self

      # 総入力を計算するnet_input
      def net_input(self, X):
          return np.dot(X, self.w_[1:]) + self.w_[0]

      # 予測値を計算するpredict
      def predict(self, X):
          return self.net_input(X)
#+end_src

#+RESULTS:

説明変数としてRM（1戸あたりの平均部屋数）を使う
#+begin_src python :session :results value
  X = df[["RM"]].values
  y = df["MEDV"].values
  from sklearn.preprocessing import StandardScaler
  sc_x = StandardScaler()
  sc_y = StandardScaler()
  X_std = sc_x.fit_transform(X)
  y_std = sc_y.fit_transform(y[:, np.newaxis]).flatten()
  lr = LinearRegressionGD()
  lr.fit(X_std, y_std)
#+end_src

#+RESULTS:
: <__main__.LinearRegressionGD object at 0x7f4826a1cda0>

#+begin_src python :session :results file link
  # エポック数とコストの関係を表す折れ線グラフのプロット
  plt.close("all")
  plt.plot(range(1, lr.n_iter + 1), lr.cost_)
  plt.ylabel("SSE")
  plt.xlabel("Epoch")

  fname = "images/10_05.png"
  plt.savefig(fname)
  fname
#+end_src

#+RESULTS:
[[file:images/10_05.png]]

線形回帰の直線が訓練データにどの程度適合しているかを可視化する

#+begin_src python :session
  def lin_regplot(X, y, model):
      plt.scatter(X, y, c = "steelblue", edgecolor = "white", s = 70)
      plt.plot(X, model.predict(X), color = "black", lw = 2)
      return None
#+end_src

#+RESULTS:

#+begin_src python :session :results file link
  plt.close("all")
  lin_regplot(X_std, y_std, lr)
  plt.xlabel("Average number of rooms [RM] (standardized)")
  plt.ylabel("Price in $1000s [MEDV] (standardized)")

  fname = "images/10_06.png"
  plt.savefig(fname)
  fname
#+end_src

#+RESULTS:
[[file:images/10_06.png]]

#+begin_src python :session :results output
  num_rooms_std = sc_x.transform(np.array([[5.0]]))
  price_std = lr.predict(num_rooms_std)
  print("Price in $1000s: %.3f" % sc_y.inverse_transform(price_std[:, np.newaxis]).flatten())
#+end_src

#+RESULTS:
: /tmp/babel-q35Ncd/python-ZEaqc6:3: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
:   print("Price in $1000s: %.3f" % sc_y.inverse_transform(price_std[:, np.newaxis]).flatten())
: Price in $1000s: 10.840

#+begin_src python :session :results output
  print("Slope: %.3f" % lr.w_[1])
  print("Intercept: %.3f" % lr.w_[0])
#+end_src

#+RESULTS:
: Slope: 0.695
: Intercept: -0.000

** scikit-learnを使って回帰モデルの係数を推定する
#+begin_src python :session :results output
  from sklearn.linear_model import LinearRegression
  slr = LinearRegression()
  slr.fit(X, y)
  y_pred = slr.predict(X)
  print("Slope: %.3f" % slr.coef_[0])
  print("Intercept: %.3f" % slr.intercept_)
#+end_src

#+RESULTS:
: Slope: 9.102
: Intercept: -34.671

#+begin_src python :session :results file link
  plt.close("all")
  lin_regplot(X, y, slr)
  plt.xlabel("Average number of rooms [RM]")
  plt.ylabel("Price in $1000s [MEDV]")

  fname = "images/10_07.png"
  plt.savefig(fname)
  fname
#+end_src

#+RESULTS:
[[file:images/10_07.png]]

* RANSACを使ったロバスト回帰モデルの学習
*RANSAC* アルゴリズム
回帰モデルにデータのサブセットいわゆる正常値を学習させる
RANSACアルゴリズムと線形モデルを組み合わせる
#+begin_src python :session :results value
  from sklearn.linear_model import RANSACRegressor
  # RANSACモデルをインスタンス化
  ransac = RANSACRegressor(LinearRegression(),
                           max_trials = 100,
                           min_samples = 50,
                           loss = "absolute_error",
                           residual_threshold = 5.0,
                           random_state = 0)
  ransac.fit(X, y)
#+end_src

#+RESULTS:
: RANSACRegressor(estimator=LinearRegression(), min_samples=50, random_state=0,
:                 residual_threshold=5.0)

#+begin_src python :session :results file link
  inlier_mask = ransac.inlier_mask_ # 正常値を表す真偽値を取得
  outlier_mask = np.logical_not(inlier_mask) # 外れ値を表す真偽値を取得
  line_X = np.arange(3, 10, 1)               # 3から9までの整数値を作成
  line_y_ransac = ransac.predict(line_X[:, np.newaxis]) # 予測値を計算
  plt.close("all")
  # 正常値をプロット
  plt.scatter(X[inlier_mask], y[inlier_mask],
              c = "steelblue", edgecolor = "white", marker = "o", label = "Inliers")
  # 外れ値をプロット
  plt.scatter(X[outlier_mask], y[outlier_mask],
              c = "limegreen", edgecolor = "white", marker = "s", label = "Outliers")
  # 予測値をプロットする
  plt.plot(line_X, line_y_ransac, color = "black", lw = 2)
  plt.xlabel("Average number of rooms [RM]")
  plt.ylabel("Price in $1000s [MEDV]")
  plt.legend(loc = "upper left")

  fname = "images/10_08.png"
  plt.savefig(fname)
  fname
#+end_src

#+RESULTS:
[[file:images/10_08.png]]

モデルの切片と傾き
#+begin_src python :session :results output
  print("Slope: %.3f" % ransac.estimator_.coef_[0])
  print("Intercept: %.3f" % ransac.estimator_.intercept_)
#+end_src

#+RESULTS:
: Slope: 10.735
: Intercept: -44.089

* 線形回帰モデルの性能評価
#+begin_src python :session :results output
  from sklearn.model_selection import train_test_split
  X = df.iloc[:, :-1].values
  y = df["MEDV"].values
  X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                      test_size = 0.3, random_state = 0)
  slr = LinearRegression()
  slr.fit(X_train, y_train)
  y_train_pred = slr.predict(X_train)
  y_test_pred = slr.predict(X_test)
#+end_src

#+RESULTS:
