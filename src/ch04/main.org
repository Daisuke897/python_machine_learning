データ前処理 よりよい訓練データセットの構築

#+begin_src emacs-lisp
  (pyvenv-activate "~/project/python_machine_learning")
#+end_src

#+RESULTS:

* 欠測データへの対処

** 表形式のデータで欠測値を特定する
#+begin_src python :session :results value
  import pandas as pd
  from io import StringIO

  csv_data = '''A,B,C,D
  1.0,2.0,3.0,4.0
  5.0,6.0,,8.0
  10.0,11.0,12.0,'''

  df = pd.read_csv(StringIO(csv_data))

  df
#+end_src

#+RESULTS:
:       A     B     C    D
: 0   1.0   2.0   3.0  4.0
: 1   5.0   6.0   NaN  8.0
: 2  10.0  11.0  12.0  NaN

#+begin_src python :session :results value
  # 各特徴量の欠測値をカウント
  df.isnull().sum()
#+end_src

#+RESULTS:
: A    0
: B    0
: C    1
: D    1
: dtype: int64

#+begin_src python :session :results value
  # 欠測値を含む行を削除
  df_copied = df.copy()
  df_copied.dropna()
#+end_src

#+RESULTS:
:      A    B    C    D
: 0  1.0  2.0  3.0  4.0

#+begin_src python :session :results value
  # 欠測値を含む列を削除
  df_copied = df.copy()
  df_copied.dropna(axis=1)
#+end_src

#+RESULTS:
:       A     B
: 0   1.0   2.0
: 1   5.0   6.0
: 2  10.0  11.0

#+begin_src python :session :results value
  # すべての列がNaNである行だけを削除
  df_copied = df.copy()
  df_copied.dropna(how="all")
#+end_src

#+RESULTS:
:       A     B     C    D
: 0   1.0   2.0   3.0  4.0
: 1   5.0   6.0   NaN  8.0
: 2  10.0  11.0  12.0  NaN

#+begin_src python :session :results value
  # 非NaN値が4つ未満の行を削除
  df_copied = df.copy()
  df_copied.dropna(thresh=4)
#+end_src

#+RESULTS:
:      A    B    C    D
: 0  1.0  2.0  3.0  4.0

#+begin_src python :session :results value
  # 特定の列にNaNが含まれている行だけを削除
  df_copied = df.copy()
  df_copied.dropna(subset=["C"])
#+end_src

#+RESULTS:
:       A     B     C    D
: 0   1.0   2.0   3.0  4.0
: 2  10.0  11.0  12.0  NaN

欠測値をすべて削除しすぎると解析の信頼性が失われる場合がある。

** 欠測値を補完する

#+begin_src python :session :results value
  from sklearn.impute import SimpleImputer
  import numpy as np
  # 欠測値補完のインスタンスを生成（平均値補完）
  imr = SimpleImputer(missing_values=np.nan, strategy="mean")
  # データを適合
  imr = imr.fit(df.values)
  # 補完を実行する
  imputed_data = imr.transform(df.values)
  imputed_data
#+end_src

#+RESULTS:
|  1 |  2 |   3 | 4 |
|  5 |  6 | 7.5 | 8 |
| 10 | 11 |  12 | 6 |

#+begin_src python :session :results value
  df.fillna(df.mean())
#+end_src

#+RESULTS:
:       A     B     C    D
: 0   1.0   2.0   3.0  4.0
: 1   5.0   6.0   7.5  8.0
: 2  10.0  11.0  12.0  6.0

* カテゴリデータの処理
順序と名義を区別する必要がある

#+begin_src python :session :results value
  import pandas as pd

  df = pd.DataFrame([
      ["green", "M", 10.1, "class2"],
      ["red", "L", 13.5, "class1"],
      ["blue", "XL", 15.3, "class2"],
  ])

  df.columns = ["color", "size", "price", "classlabel"]
  df
#+end_src

#+RESULTS:
:    color size  price classlabel
: 0  green    M   10.1     class2
: 1    red    L   13.5     class1
: 2   blue   XL   15.3     class2

** 順序特徴量のマッピング
#+begin_src python :session :results value
  # Tシャツのサイズと整数を対応させるディクショナリを生成
  size_mapping = {"XL": 3, "L": 2, "M": 1}
  # Tシャツのサイズを整数に変換
  df["size"] = df["size"].map(size_mapping)
  df
#+end_src

#+RESULTS:
:    color  size  price classlabel
: 0  green     1   10.1     class2
: 1    red     2   13.5     class1
: 2   blue     3   15.3     class2

逆に戻したい場合

#+begin_src python :session :results value
  inv_size_mapping = {v: k for k, v in size_mapping.items()}

  df["size"].map(inv_size_mapping)
#+end_src

#+RESULTS:
: 0     M
: 1     L
: 2    XL
: Name: size, dtype: object

** クラスラベルのエンコーディング
多くの機械学習ライブラリは、クラスラベルが整数値としてエンコードされていることを要求する
#+begin_src python :session :results value
  import numpy as np
  # クラスラベルと整数を対応させるディクショナリを作成
  class_mapping = {label: idx for idx, label in enumerate(np.unique(df["classlabel"]))}
  class_mapping
#+end_src

#+RESULTS:
| class1 | : | 0 | class2 | : | 1 |

マッピングディクショナリを作成したらクラスラベルを整数に変換できる
#+begin_src python :session :results value
  # クラスラベルを整数に変換
  df["classlabel"] = df["classlabel"].map(class_mapping)

  df
#+end_src

#+RESULTS:
:    color  size  price  classlabel
: 0  green     1   10.1           1
: 1    red     2   13.5           0
: 2   blue     3   15.3           1

逆に戻す

#+begin_src python :session :results value
  # 整数とクラスラベルを対応させるディクショナリを作成
  inv_class_mapping = {v: k for k, v in class_mapping.items()}

  df["classlabel"] = df["classlabel"].map(inv_class_mapping)
  df
#+end_src

#+RESULTS:
:    color  size  price classlabel
: 0  green     1   10.1     class2
: 1    red     2   13.5     class1
: 2   blue     3   15.3     class2

scikit_learn の LabelEncoder というクラスを使う手がある
#+begin_src python :session :results value
  from sklearn.preprocessing import LabelEncoder

  class_le = LabelEncoder()

  y = class_le.fit_transform(df["classlabel"].values)

  y
#+end_src

#+RESULTS:
| 1 | 0 | 1 |

もとの文字列に戻すこともできる
#+begin_src python :session :results value
  class_le.inverse_transform(y)
#+end_src

#+RESULTS:
| class2 | class1 | class2 |


** one-hotエンコーディング

#+begin_src python :session :results value
  from sklearn.preprocessing import OneHotEncoder
  X = df[["color", "size", "price"]].values

  color_ohe = OneHotEncoder()

  color_ohe.fit_transform(X[:, 0].reshape(-1, 1)).toarray()
#+end_src

#+RESULTS:
| 0 | 1 | 0 |
| 0 | 0 | 1 |
| 1 | 0 | 0 |

複数の特徴量からなる配列の列を選択的に変換したい場合は、ColumnTransformerを使うことができる

#+begin_src python :session :results value
  from sklearn.compose import ColumnTransformer

  X = df[["color", "size", "price"]].values

  c_transf = ColumnTransformer(
      [("onehot", OneHotEncoder(), [0]),
       ("nothing", "passthrough", [1, 2])]
  )

  c_transf.fit_transform(X).astype(float)
#+end_src

#+RESULTS:
| 0 | 1 | 0 | 1 | 10.1 |
| 0 | 0 | 1 | 2 | 13.5 |
| 1 | 0 | 0 | 3 | 15.3 |

#+begin_src python :session :results value
  pd.get_dummies(df[["price", "color", "size"]])
#+end_src

#+RESULTS:
:    price  size  color_blue  color_green  color_red
: 0   10.1     1       False         True      False
: 1   13.5     2       False        False       True
: 2   15.3     3        True        False      False

冗長な列（最初の列）を削除する
#+begin_src python :session :results value
  pd.get_dummies(df[["price", "color", "size"]], drop_first=True)
#+end_src

#+RESULTS:
:    price  size  color_green  color_red
: 0   10.1     1         True      False
: 1   13.5     2        False       True
: 2   15.3     3        False      False

#+begin_src python :session :results value
  color_ohe = OneHotEncoder(categories="auto", drop="first")
  c_transf = ColumnTransformer([("onehot", color_ohe, [0]),
                                ("nothing", "passthrough", [1, 2])])
  c_transf.fit_transform(X).astype(float)
#+end_src

#+RESULTS:
| 1 | 0 | 1 | 10.1 |
| 0 | 1 | 2 | 13.5 |
| 0 | 0 | 3 | 15.3 |

* テストデータを訓練データセットとテストデータセットに分割する
#+begin_src python :session :results value
  import numpy as np
  import pandas as pd

  df_wine = pd.read_csv(
      'https://archive.ics.uci.edu/'
      'ml/machine-learning-databases/wine/wine.data',
      header=None
  )
  df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash',
                     'Alcalinity of ash', 'Magnesium', 'Total phenols',
                     'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',
                     'Color intensity', 'Hue', 'OD280/OD315 of diluted wines',
                     'Proline']


  print('Class labels', np.unique(df_wine['Class label']))
  df_wine.head()
#+end_src

#+RESULTS:
:    Class label  Alcohol  ...  OD280/OD315 of diluted wines  Proline
: 0            1    14.23  ...                          3.92     1065
: 1            1    13.20  ...                          3.40     1050
: 2            1    13.16  ...                          3.17     1185
: 3            1    14.37  ...                          3.45     1480
: 4            1    13.24  ...                          2.93      735
: 
: [5 rows x 14 columns]

#+begin_src python :session :results value
  from sklearn.model_selection import train_test_split

  X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values

  X_train, X_test, y_train, y_test = \
      train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)
#+end_src

#+RESULTS:

* 特徴量の尺度を揃える
正規化は特徴量を[0, 1]の範囲にスケーリングし直すことを意味する
#+begin_src python :session :results value
  from sklearn.preprocessing import MinMaxScaler

  mms = MinMaxScaler()

  X_train_norm = mms.fit_transform(X_train)

  X_test_norm = mms.transform(X_test)
#+end_src

#+RESULTS:

標準化は、平均値0、標準偏差1となるように変換する
#+begin_src python :session :results output
  ex = np.array([0, 1, 2, 3, 4, 5])
  print("standardized:", (ex - ex.mean()) / ex.std())
  print("normalized:", (ex - ex.min()) / (ex.max() - ex.min()))
#+end_src

#+RESULTS:
: standardized: [-1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011]
: normalized: [0.  0.2 0.4 0.6 0.8 1. ]
