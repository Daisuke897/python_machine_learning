*モデルの評価とハイパーパラメータのチューニングのベストプラクティス*

#+begin_src emacs-lisp
  (pyvenv-activate "~/project/python_machine_learning")
#+end_src

#+RESULTS:

* パイプラインによるワークフローの効率化
** Breast Cancer Wisconsin データセットを読み込む

#+begin_src python :session :results output
  import pandas as pd
  df = pd.read_csv("https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data", header=None)
#+end_src

#+RESULTS:

#+begin_src python :session :results value
  df.head()
#+end_src

#+RESULTS:
:          0  1      2      3   ...      28      29      30       31
: 0    842302  M  17.99  10.38  ...  0.7119  0.2654  0.4601  0.11890
: 1    842517  M  20.57  17.77  ...  0.2416  0.1860  0.2750  0.08902
: 2  84300903  M  19.69  21.25  ...  0.4504  0.2430  0.3613  0.08758
: 3  84348301  M  11.42  20.38  ...  0.6869  0.2575  0.6638  0.17300
: 4  84358402  M  20.29  14.34  ...  0.4000  0.1625  0.2364  0.07678
: 
: [5 rows x 32 columns]

30個の特徴量をNumpy配列Xに割り当てる。
LabelEncoderを使って、元のクラスラベルの文字列表現 ("M", "B") を整数に変換する

#+begin_src python :session :results value
  from sklearn.preprocessing import LabelEncoder
  X = df.loc[:, 2:].values
  y = df.loc[:, 1].values
  le = LabelEncoder()
  y = le.fit_transform(y)
  le.classes_
#+end_src

#+RESULTS:
| B | M |

#+begin_src python :session :results value
  le.transform(["M", "B"])

#+end_src

#+RESULTS:
| 1 | 0 |

テストデータを訓練データセット (80%) とテストデータセット (20%) に分割する
#+begin_src python :session :results value
  from sklearn.model_selection import train_test_split

  X_train, X_test, y_train, y_test = train_test_split(
      X, y, test_size = 0.20, stratify = y, random_state = 1
  )
#+end_src

#+RESULTS:
** パイプラインで変換器と推定器を結合する
#+begin_src python :session :results output
  from sklearn.preprocessing import StandardScaler
  from sklearn.decomposition import PCA
  from sklearn.linear_model import LogisticRegression
  from sklearn.pipeline import make_pipeline

  # 連結する処理としてスケーリング、主成分分析、ロジスティック回帰を指定
  pipe_lr = make_pipeline(StandardScaler(),
                          PCA(n_components = 2),
                          LogisticRegression(random_state = 1, solver = "lbfgs"))
  pipe_lr.fit(X_train, y_train)
  y_pred = pipe_lr.predict(X_test)

  print("Test Accuracy: %.3f" % pipe_lr.score(X_test, y_test))
#+end_src

#+RESULTS:
: Test Accuracy: 0.956

