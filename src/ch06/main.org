*モデルの評価とハイパーパラメータのチューニングのベストプラクティス*

#+begin_src emacs-lisp
  (pyvenv-activate "~/project/python_machine_learning")
#+end_src

#+RESULTS:

* パイプラインによるワークフローの効率化
** Breast Cancer Wisconsin データセットを読み込む

#+begin_src python :session :results output
  import pandas as pd
  df = pd.read_csv("https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data", header=None)
#+end_src

#+RESULTS:

#+begin_src python :session :results value
  df.head()
#+end_src

#+RESULTS:
:          0  1      2      3   ...      28      29      30       31
: 0    842302  M  17.99  10.38  ...  0.7119  0.2654  0.4601  0.11890
: 1    842517  M  20.57  17.77  ...  0.2416  0.1860  0.2750  0.08902
: 2  84300903  M  19.69  21.25  ...  0.4504  0.2430  0.3613  0.08758
: 3  84348301  M  11.42  20.38  ...  0.6869  0.2575  0.6638  0.17300
: 4  84358402  M  20.29  14.34  ...  0.4000  0.1625  0.2364  0.07678
:
: [5 rows x 32 columns]

30個の特徴量をNumpy配列Xに割り当てる。
LabelEncoderを使って、元のクラスラベルの文字列表現 ("M", "B") を整数に変換する

#+begin_src python :session :results value
  from sklearn.preprocessing import LabelEncoder
  X = df.loc[:, 2:].values
  y = df.loc[:, 1].values
  le = LabelEncoder()
  y = le.fit_transform(y)
  le.classes_
#+end_src

#+RESULTS:
| B | M |

#+begin_src python :session :results value
  le.transform(["M", "B"])

#+end_src

#+RESULTS:
| 1 | 0 |

テストデータを訓練データセット (80%) とテストデータセット (20%) に分割する
#+begin_src python :session :results value
  from sklearn.model_selection import train_test_split

  X_train, X_test, y_train, y_test = train_test_split(
      X, y, test_size = 0.20, stratify = y, random_state = 1
  )
#+end_src

#+RESULTS:
** パイプラインで変換器と推定器を結合する
#+begin_src python :session :results output
  from sklearn.preprocessing import StandardScaler
  from sklearn.decomposition import PCA
  from sklearn.linear_model import LogisticRegression
  from sklearn.pipeline import make_pipeline

  # 連結する処理としてスケーリング、主成分分析、ロジスティック回帰を指定
  pipe_lr = make_pipeline(StandardScaler(),
                          PCA(n_components = 2),
                          LogisticRegression(random_state = 1, solver = "lbfgs"))
  pipe_lr.fit(X_train, y_train)
  y_pred = pipe_lr.predict(X_test)

  print("Test Accuracy: %.3f" % pipe_lr.score(X_test, y_test))
#+end_src

#+RESULTS:
: Test Accuracy: 0.956

* k分割交差検証を使ったモデルの性能の評価

** ホールドアウト法
データを訓練データセット、検証データセット、テストデータセットの3つに分割する

** k分割交差検証
非復元情報を用いて、訓練データセットをランダムにk個に分割する。
このうちのk-1個をモデルの訓練に使い、1個を性能の評価に使う。
このk個のモデルを取得し、性能を推定する。

*層化k分割交差検証*
訓練データセット全体でのクラスレベルの比率が維持される。

#+begin_src python :session :results output
  import numpy as np
  from sklearn.model_selection import StratifiedKFold
  # 分割元データ、分割数、乱数生成器の状態を指定し、
  # 層化K分割交差検証イテレータを表すStratifiedKFoldクラスのインスタンス化
  kfold = StratifiedKFold(n_splits = 10).split(X_train, y_train)
  scores = []
  # イテレータのインデックスと要素をループ処理：（上から順に）
  # データをモデルに適合
  # テストデータの正解率を算出
  # リストに正解率を追加
  # 分割の番号、0以上の要素数、正解率を出力
  for k, (train, test) in enumerate(kfold):
      pipe_lr.fit(X_train[train], y_train[train])
      score = pipe_lr.score(X_train[test], y_train[test])
      scores.append(score)
      print("Fold: %2d, Class dist.: %s, Acc: %.3f" % (k + 1, np.bincount(y_train[train]), score))

  # 正解率の平均と標準偏差を出力
  print("\nCV accuracy: %.3f +/- %.3f" % (np.mean(scores), np.std(scores)))

#+end_src

#+RESULTS:
#+begin_example
Fold:  1, Class dist.: [256 153], Acc: 0.935
Fold:  2, Class dist.: [256 153], Acc: 0.935
Fold:  3, Class dist.: [256 153], Acc: 0.957
Fold:  4, Class dist.: [256 153], Acc: 0.957
Fold:  5, Class dist.: [256 153], Acc: 0.935
Fold:  6, Class dist.: [257 153], Acc: 0.956
Fold:  7, Class dist.: [257 153], Acc: 0.978
Fold:  8, Class dist.: [257 153], Acc: 0.933
Fold:  9, Class dist.: [257 153], Acc: 0.956
Fold: 10, Class dist.: [257 153], Acc: 0.956

CV accuracy: 0.950 +/- 0.014
#+end_example

#+begin_src python :session :results output
  from sklearn.model_selection import cross_val_score
  # 交差検証のcross_val_score関数でモデルの正解率を算出
  # 推定器 estimator, 訓練データX, 予測データy, 分割数cv, CPU数n_jobsを推定
  scores = cross_val_score(estimator=pipe_lr,
                           X=X_train, y=y_train,
                           cv=10, n_jobs=1)
  print("CV accuracy scores: %s" % scores)
  print("CV accuracy: %.3f +/- %.3f" % (np.mean(scores), np.std(scores)))
#+end_src

#+RESULTS:
: CV accuracy scores: [0.93478261 0.93478261 0.95652174 0.95652174 0.93478261 0.95555556
:  0.97777778 0.93333333 0.95555556 0.95555556]
: CV accuracy: 0.950 +/- 0.014

* 学習曲線と検証曲線によるアルゴリズムの診断

** 学習曲線を使ってバイアスとバリアンスの問題を診断する
過学習の問題に対処するには、訓練データをさらに収集するか、正則化のパラメータを増やすなどして、モデルの複雑さを抑えれば良い

#+begin_src python :session :results file link
  import numpy as np
  import matplotlib.pyplot as plt
  from sklearn.preprocessing import StandardScaler
  from sklearn.linear_model import LogisticRegression
  from sklearn.pipeline import make_pipeline
  from sklearn.model_selection import learning_curve
  pipe_lr = make_pipeline(
      StandardScaler(),
      LogisticRegression(penalty = "l2", random_state = 1,
                         solver = "lbfgs", max_iter = 10000)
  )
  # learning_curve関数で交差検証による正解率を算出
  train_sizes, train_scores, test_scores = learning_curve(
      estimator = pipe_lr,
      X = X_train, y = y_train,
      train_sizes = np.linspace(0.1, 1.0, 10),
      cv = 10, n_jobs = 1
  )
  train_mean = np.mean(train_scores, axis = 1)
  train_std = np.std(train_scores, axis = 1)
  test_mean = np.mean(test_scores, axis = 1)
  test_std = np.std(test_scores, axis = 1)

  plt.close("all")

  plt.plot(
      train_sizes, train_mean,
      color = "blue", marker = "o",
      markersize = 5, label = "Training accuracy"
  )

  # fill_between関数で平均+-標準偏差の幅を塗りつぶす
  # 訓練データのサイズtrain_sizes, 透明度alpha, カラー"blue"引数に指定
  plt.fill_between(
      train_sizes,
      train_mean + train_std,
      train_mean - train_std,
      alpha = 0.15,
      color = "blue"
  )

  plt.plot(
      train_sizes, test_mean,
      color = "green", linestyle = "--", marker = "s",
      markersize = 5, label = "Validation accuracy"
  )

  plt.fill_between(
      train_sizes,
      test_mean + test_std,
      test_mean - test_std,
      alpha = 0.15,
      color = "green"
  )

  plt.grid()

  plt.xlabel("Number of training examples")
  plt.ylabel("Accuracy")
  plt.legend(loc = "lower right")
  plt.ylim([0.8, 1.03])
  plt.tight_layout()

  fname = "images/06_05.png"

  plt.savefig(fname)

  fname
#+end_src

#+RESULTS:
[[file:images/06_05.png]]

** 検証曲線を使って過学習と学習不足を明らかにする
#+begin_src python :session :results file link
  from sklearn.model_selection import validation_curve
  param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]
  # validation_curve関数によりモデルのパラメータを変化させ、交差検証による正解値を算出
  # clf__CはLogisticRegressionオブジェクトのパラメータ
  train_scores, test_scores = validation_curve(estimator=pipe_lr,
                                               X=X_train, y=y_train,
                                               param_name="logisticregression__C",
                                               param_range=param_range, cv=10)
  train_mean = np.mean(train_scores, axis = 1)
  train_std = np.std(train_scores, axis = 1)
  test_mean = np.mean(test_scores, axis = 1)
  test_std = np.std(test_scores, axis = 1)

  plt.close("all")

  plt.plot(
      param_range, train_mean,
      color = "blue", marker = "o",
      markersize = 5, label = "Training accuracy"
  )

  plt.fill_between(
      param_range,
      train_mean + train_std,
      train_mean - train_std,
      alpha = 0.15,
      color = "blue"
  )

  plt.plot(
      param_range, test_mean,
      color = "green", linestyle = "--", marker = "s",
      markersize = 5, label = "Validation accuracy"
  )

  plt.fill_between(
      param_range,
      test_mean + test_std,
      test_mean - test_std,
      alpha = 0.15,
      color = "green"
  )

  plt.grid()
  plt.xscale("log")
  plt.legend(loc="lower right")
  plt.xlabel("Parameter C")
  plt.ylabel("Accuracy")
  plt.ylim([0.8, 1.0])

  plt.tight_layout()

  fname = "images/06_06.png"

  plt.savefig(fname)

  fname
#+end_src

#+RESULTS:
[[file:images/06_06.png]]

C = 0.01 ~ 0.1あたりが最適

* グリッドサーチによる機械学習モデルのチューニング

** グリッドサーチを使ったハイパーパラメータのチューニング
#+begin_src python :session :results output
  from sklearn.model_selection import GridSearchCV
  from sklearn.pipeline import make_pipeline
  from sklearn.preprocessing import StandardScaler
  from sklearn.svm import SVC

  pipe_svc = make_pipeline(StandardScaler(), SVC(random_state=1))
  param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]
  param_grid = [{"svc__C": param_range, "svc__kernel": ["linear"]},
                {"svc__C": param_range, "svc__gamma": param_range, "svc__kernel": ["rbf"]}]
  # ハイパーパラメータ値のリストparam_gridを指定し、
  # グリッドサーチを行うGridSearchCVクラスをインスタンス化
  gs = GridSearchCV(estimator = pipe_svc,
                    param_grid = param_grid,
                    scoring = "accuracy", cv = 10, refit = True, n_jobs = -1)
  gs = gs.fit(X_train, y_train)
  # モデルの最良スコアを出力
  print(gs.best_score_)
  # 最良スコアとなるパラメータ値を出力
  print(gs.best_params_)
#+end_src

#+RESULTS:
: 0.9846859903381642
: {'svc__C': 100.0, 'svc__gamma': 0.001, 'svc__kernel': 'rbf'}

テストデータを用いてモデル性能を評価する
#+begin_src python :session :results output
  clf = gs.best_estimator_
  # clf.fit(X_train, y_train)
  print("Test accuracy: %.3f" % clf.score(X_test, y_test))
#+end_src

#+RESULTS:
: Test accuracy: 0.974

** 入れ子式の交差検証によるアルゴリズムの選択
入れ子式の交差検証では、外側のループでk分割交差検証を使うことで、データを訓練サブセットとテストサブセットに分割する。
内側のループでは、訓練データセットに対してk分割交差検証を行うことで、モデルを選択する。
モデルを選択した後、テストデータセットを使ってモデル性能を評価する。

#+begin_src python :session :results output
  import numpy as np
  from sklearn.model_selection import cross_val_score
  gs = GridSearchCV(estimator = pipe_svc,
                    param_grid = param_grid,
                    scoring = "accuracy", cv = 2)

  scores = cross_val_score(gs, X_train, y_train, scoring = "accuracy", cv = 5)

  print("CV accuracy: %.3f +/- %.3f" % (np.mean(scores), np.std(scores)))
#+end_src

#+RESULTS:
: CV accuracy: 0.974 +/- 0.015

対象として、決定木の深さパラメータをチューニングする
#+begin_src python :session :results output
  from sklearn.tree import DecisionTreeClassifier
  # ハイパーパラメータ値として決定木の深さパラメータを指定し、
  # グリッドサーチを行うGridSearchCVクラスをインスタンス化
  gs = GridSearchCV(estimator = DecisionTreeClassifier(random_state = 0),
                    param_grid = [{"max_depth": [1, 2, 3, 4, 5, 6, 7, None]}],
                    scoring = "accuracy", cv = 2)
  scores = cross_val_score(gs,
                           X_train, y_train,
                           scoring = "accuracy",
                           cv = 5)
  print("CV accuracy: %.3f +/- %.3f" % (np.mean(scores), np.std(scores)))
#+end_src

#+RESULTS:
: CV accuracy: 0.934 +/- 0.016

* さまざまな性能評価手法

** 混同行列を解釈する
混同行列は、分類器の *真陽性*, *真陰性*, *偽陽性*, *偽陰性* の4つ予測の個数を報告する単なる正方行列である。

#+begin_src python :session :results output
  from sklearn.metrics import confusion_matrix
  pipe_svc.fit(X_train, y_train)
  y_pred = pipe_svc.predict(X_test)
  # テストと予測のデータから混同行列を生成
  confmat = confusion_matrix(y_true = y_test, y_pred = y_pred)
  print(confmat)
#+end_src

#+RESULTS:
: [[71  1]
:  [ 2 40]]

誤分類に関する情報を対応付けるには、matplotlibのmatshow関数を使う。
#+begin_src python :session :results file link
  import matplotlib.pyplot as plt
  plt.close("all")
  # 図のサイズを指定
  fig, ax = plt.subplots(figsize = (2.5, 2.5))
  # matshow関数で行列からヒートマップを描画
  ax.matshow(confmat, cmap = plt.cm.Blues, alpha = 0.3)
  for i in range(confmat.shape[0]):     # クラス0の繰り返し処理
      for j in range(confmat.shape[1]): # クラス1の繰り返し処理
          ax.text(x = j, y = i, s = confmat[i, j], va = "center", ha = "center") # 件数を表示

  plt.xlabel("Predicted label")
  plt.ylabel("True label")
  plt.tight_layout()

  fname = "images/06_09.png"

  plt.savefig(fname)

  fname
#+end_src

#+RESULTS:
[[file:images/06_09.png]]

** 分類モデルの適合率と再現率を最適化する

#+begin_src python :session :results output
  # 適合率、再現率、F1スコアを出力
  from sklearn.metrics import precision_score
  from sklearn.metrics import recall_score, f1_score
  print("Precision: %.3f" % precision_score(y_true = y_test, y_pred = y_pred))
  print("Recall: %.3f" % recall_score(y_true = y_test, y_pred = y_pred))
  print("F1: %.3f" % f1_score(y_true = y_test, y_pred = y_pred))
#+end_src

#+RESULTS:
: Precision: 0.976
: Recall: 0.952
: F1: 0.964

#+begin_src python :session :results output
  # カスタムの性能指標を出力
  from sklearn.metrics import make_scorer, f1_score
  c_gamma_range = [0.01, 0.1, 1.0, 10.0]
  param_grid = [{"svc__C": c_gamma_range, "svc__kernel": ["linear"]},
                {"svc__C": c_gamma_range, "svc__gamma": c_gamma_range, "svc__kernel": ["rbf"]}]
  scorer = make_scorer(f1_score, pos_label = 0)
  gs = GridSearchCV(estimator = pipe_svc,
                    param_grid = param_grid,
                    scoring = scorer,
                    cv = 10, n_jobs = -1)
  gs = gs.fit(X_train, y_train)
  print(gs.best_score_)
  print(gs.best_params_)

#+end_src

#+RESULTS:
: 0.9861994953378878
: {'svc__C': 10.0, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}

** ROC曲線をプロットする

#+begin_src python :session :results link file
  from sklearn.metrics import roc_curve, auc
  from numpy import interp
  # スケーリング、主成分分析、ロジスティック回帰を指定して、Pipelineクラスをインスタンス化
  pipe_lr = make_pipeline(StandardScaler(), PCA(n_components = 2),
                          LogisticRegression(penalty = "l2", random_state = 1,
                                             solver = "lbfgs", C = 100.0))
  # 2つの特徴量を抽出
  X_train2 = X_train[:, [4, 14]]
  # 層化k分割交差検証イテレータを表すStratifiedKFoldクラスをインスタンス化
  cv = list(StratifiedKFold(n_splits = 3).split(X_train, y_train))
  plt.close("all")
  fig = plt.figure(figsize = (7, 5))
  mean_tpr = 0.0

  # 0から1までの間で100個の要素を生成
  mean_fpr = np.linspace(0, 1, 100)
  all_tpr = []

  for i, (train, test) in enumerate(cv):
      # predict_probaメゾットで確率予測、fitメゾットでモデルに適合させる
      probas = pipe_lr.fit(X_train2[train],
                           y_train[train]).predict_proba(X_train2[test])
      # roc_curve関数でROC曲線の性能を計算してプロット
      fpr, tpr, thresholds = roc_curve(y_train[test], probas[:, 1], pos_label = 1)
      mean_tpr += interp(mean_fpr, fpr, tpr) # FPR(X軸)とTPR(Y軸)を線形補間
      mean_tpr[0] = 0.0
      roc_auc = auc(fpr, tpr)
      plt.plot(fpr, tpr, label = "ROC fold %d (area = %0.2f)" % (i + 1, roc_auc))

  # 当て推量をプロット
  plt.plot([0, 1], [0, 1],
           linestyle = "--", color = (0.6, 0.6, 0.6), label = "Random guessing")
  # FPR, TPR, ROC AUCそれぞれの平均を計算してプロット
  mean_tpr /= len(cv)
  mean_tpr[-1] = 1.0
  mean_auc = auc(mean_fpr, mean_tpr)
  plt.plot(mean_fpr, mean_tpr, "k--",
           label = "Mean ROC (area = %0.2f)" % mean_auc, lw = 2)
  # 完全に予測が正解したときのROC曲線をプロット
  plt.plot([0, 0, 1], [0, 1, 1],
           linestyle = ":", color = "black", label = "Perfect performance")
  # グラフの各項目を指定
  plt.xlim([-0.05, 1.05])
  plt.ylim([-0.05, 1.05])
  plt.xlabel("False positive rate")
  plt.ylabel("True positive rate")
  plt.legend(loc = "lower right")
  plt.tight_layout()

  fname = "images/06_10.png"

  plt.savefig(fname)

  fname
#+end_src

#+RESULTS:
[[file:images/06_10.png]]

** 多クラス分類のための性能指標
マイクロ平均は各クラスの真陽性、真陰性、偽陽性、偽陰性から計算される。
マクロ平均はそれぞれの問題の性能指標の平均として求める。

#+begin_src python :session :results value
  from sklearn.metrics import make_scorer
  from sklearn.metrics import precision_score
  pre_scorer = make_scorer(score_func=precision_score,
                           pos_label=1,
                           greater_is_better=True,
                           average='micro')
  pre_scorer
#+end_src

#+RESULTS:
: make_scorer(precision_score, response_method='predict', pos_label=1, average=micro)

* クラスの不均衡に対処する
不均衡なデータセットで分類器を適合させる場合には、正解率以外の性能指標（適合率、再現率、ROC曲線など）を調べるのが合理的
クラスの不均衡な割合に対処する方法の1つは、少数派クラスに関する誤った予測に大きなペナルティを課す。
sckit-learnには、resampleという関数が実装されている。
この関数はデータセットから新しいデータ点を復元抽出する。
#+begin_src python :session
  import numpy as np
  X_imb = np.vstack((X[y == 0], X[y == 1][:40]))
  y_imb = np.hstack((y[y == 0], y[y == 1][:40]))
#+end_src

#+RESULTS:

#+begin_src python :session :results value
  y_pred = np.zeros(y_imb.shape[0])
  np.mean(y_pred == y_imb) * 100
#+end_src

#+RESULTS:
: 89.92443324937027

#+begin_src python :session :results output
  from sklearn.utils import resample
  print("Number of class 1 examples before:", X_imb[y_imb == 1].shape[0])
  # データ点の個数がクラス0と同じになるまで新しいデータ点を復元抽出
  X_upsampled, y_upsampled = resample(X_imb[y_imb == 1],
                                      y_imb[y_imb == 1],
                                      replace = True,
                                      n_samples = X_imb[y_imb == 0].shape[0],
                                      random_state = 123)
  print("Number of class 1 examples after:", X_upsampled.shape[0])
#+end_src

#+RESULTS:
: Number of class 1 examples before: 40
: Number of class 1 examples after: 357

#+begin_src python :session
  X_bal = np.vstack((X[y == 0], X_upsampled))
  y_bal = np.hstack((y[y == 0], y_upsampled))
#+end_src

#+RESULTS:

#+begin_src python :session :results value
  y_pred = np.zeros(y_bal.shape[0])
  np.mean(y_pred == y_bal) * 100
#+end_src

#+RESULTS:
: 50.0
