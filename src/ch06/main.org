*モデルの評価とハイパーパラメータのチューニングのベストプラクティス*

#+begin_src emacs-lisp
  (pyvenv-activate "~/project/python_machine_learning")
#+end_src

#+RESULTS:

* パイプラインによるワークフローの効率化
** Breast Cancer Wisconsin データセットを読み込む

#+begin_src python :session :results output
  import pandas as pd
  df = pd.read_csv("https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data", header=None)
#+end_src

#+RESULTS:

#+begin_src python :session :results value
  df.head()
#+end_src

#+RESULTS:
:          0  1      2      3   ...      28      29      30       31
: 0    842302  M  17.99  10.38  ...  0.7119  0.2654  0.4601  0.11890
: 1    842517  M  20.57  17.77  ...  0.2416  0.1860  0.2750  0.08902
: 2  84300903  M  19.69  21.25  ...  0.4504  0.2430  0.3613  0.08758
: 3  84348301  M  11.42  20.38  ...  0.6869  0.2575  0.6638  0.17300
: 4  84358402  M  20.29  14.34  ...  0.4000  0.1625  0.2364  0.07678
: 
: [5 rows x 32 columns]

30個の特徴量をNumpy配列Xに割り当てる。
LabelEncoderを使って、元のクラスラベルの文字列表現 ("M", "B") を整数に変換する

#+begin_src python :session :results value
  from sklearn.preprocessing import LabelEncoder
  X = df.loc[:, 2:].values
  y = df.loc[:, 1].values
  le = LabelEncoder()
  y = le.fit_transform(y)
  le.classes_
#+end_src

#+RESULTS:
| B | M |

#+begin_src python :session :results value
  le.transform(["M", "B"])

#+end_src

#+RESULTS:
| 1 | 0 |

テストデータを訓練データセット (80%) とテストデータセット (20%) に分割する
#+begin_src python :session :results value
  from sklearn.model_selection import train_test_split

  X_train, X_test, y_train, y_test = train_test_split(
      X, y, test_size = 0.20, stratify = y, random_state = 1
  )
#+end_src

#+RESULTS:
** パイプラインで変換器と推定器を結合する
#+begin_src python :session :results output
  from sklearn.preprocessing import StandardScaler
  from sklearn.decomposition import PCA
  from sklearn.linear_model import LogisticRegression
  from sklearn.pipeline import make_pipeline

  # 連結する処理としてスケーリング、主成分分析、ロジスティック回帰を指定
  pipe_lr = make_pipeline(StandardScaler(),
                          PCA(n_components = 2),
                          LogisticRegression(random_state = 1, solver = "lbfgs"))
  pipe_lr.fit(X_train, y_train)
  y_pred = pipe_lr.predict(X_test)

  print("Test Accuracy: %.3f" % pipe_lr.score(X_test, y_test))
#+end_src

#+RESULTS:
: Test Accuracy: 0.956

* k分割交差検証を使ったモデルの性能の評価

** ホールドアウト法
データを訓練データセット、検証データセット、テストデータセットの3つに分割する

** k分割交差検証
非復元情報を用いて、訓練データセットをランダムにk個に分割する。
このうちのk-1個をモデルの訓練に使い、1個を性能の評価に使う。
このk個のモデルを取得し、性能を推定する。

*層化k分割交差検証*
訓練データセット全体でのクラスレベルの比率が維持される。

#+begin_src python :session :results output
  import numpy as np
  from sklearn.model_selection import StratifiedKFold
  # 分割元データ、分割数、乱数生成器の状態を指定し、
  # 層化K分割交差検証イテレータを表すStratifiedKFoldクラスのインスタンス化
  kfold = StratifiedKFold(n_splits = 10).split(X_train, y_train)
  scores = []
  # イテレータのインデックスと要素をループ処理：（上から順に）
  # データをモデルに適合
  # テストデータの正解率を算出
  # リストに正解率を追加
  # 分割の番号、0以上の要素数、正解率を出力
  for k, (train, test) in enumerate(kfold):
      pipe_lr.fit(X_train[train], y_train[train])
      score = pipe_lr.score(X_train[test], y_train[test])
      scores.append(score)
      print("Fold: %2d, Class dist.: %s, Acc: %.3f" % (k + 1, np.bincount(y_train[train]), score))

  # 正解率の平均と標準偏差を出力
  print("\nCV accuracy: %.3f +/- %.3f" % (np.mean(scores), np.std(scores)))

#+end_src

#+RESULTS:
#+begin_example
Fold:  1, Class dist.: [256 153], Acc: 0.935
Fold:  2, Class dist.: [256 153], Acc: 0.935
Fold:  3, Class dist.: [256 153], Acc: 0.957
Fold:  4, Class dist.: [256 153], Acc: 0.957
Fold:  5, Class dist.: [256 153], Acc: 0.935
Fold:  6, Class dist.: [257 153], Acc: 0.956
Fold:  7, Class dist.: [257 153], Acc: 0.978
Fold:  8, Class dist.: [257 153], Acc: 0.933
Fold:  9, Class dist.: [257 153], Acc: 0.956
Fold: 10, Class dist.: [257 153], Acc: 0.956

CV accuracy: 0.950 +/- 0.014
#+end_example

#+begin_src python :session :results output
  from sklearn.model_selection import cross_val_score
  # 交差検証のcross_val_score関数でモデルの正解率を算出
  # 推定器 estimator, 訓練データX, 予測データy, 分割数cv, CPU数n_jobsを推定
  scores = cross_val_score(estimator=pipe_lr,
                           X=X_train, y=y_train,
                           cv=10, n_jobs=1)
  print("CV accuracy scores: %s" % scores)
  print("CV accuracy: %.3f +/- %.3f" % (np.mean(scores), np.std(scores)))
#+end_src

#+RESULTS:
: CV accuracy scores: [0.93478261 0.93478261 0.95652174 0.95652174 0.93478261 0.95555556
:  0.97777778 0.93333333 0.95555556 0.95555556]
: CV accuracy: 0.950 +/- 0.014
