*モデルの評価とハイパーパラメータのチューニングのベストプラクティス*

#+begin_src emacs-lisp
  (pyvenv-activate "~/project/python_machine_learning")
#+end_src

#+RESULTS:

* パイプラインによるワークフローの効率化
** Breast Cancer Wisconsin データセットを読み込む

#+begin_src python :session :results output
  import pandas as pd
  df = pd.read_csv("https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data", header=None)
#+end_src

#+RESULTS:

#+begin_src python :session :results value
  df.head()
#+end_src

#+RESULTS:
:          0  1      2      3   ...      28      29      30       31
: 0    842302  M  17.99  10.38  ...  0.7119  0.2654  0.4601  0.11890
: 1    842517  M  20.57  17.77  ...  0.2416  0.1860  0.2750  0.08902
: 2  84300903  M  19.69  21.25  ...  0.4504  0.2430  0.3613  0.08758
: 3  84348301  M  11.42  20.38  ...  0.6869  0.2575  0.6638  0.17300
: 4  84358402  M  20.29  14.34  ...  0.4000  0.1625  0.2364  0.07678
: 
: [5 rows x 32 columns]

30個の特徴量をNumpy配列Xに割り当てる。
LabelEncoderを使って、元のクラスラベルの文字列表現 ("M", "B") を整数に変換する

#+begin_src python :session :results value
  from sklearn.preprocessing import LabelEncoder
  X = df.loc[:, 2:].values
  y = df.loc[:, 1].values
  le = LabelEncoder()
  y = le.fit_transform(y)
  le.classes_
#+end_src

#+RESULTS:
| B | M |

#+begin_src python :session :results value
  le.transform(["M", "B"])

#+end_src

#+RESULTS:
| 1 | 0 |

テストデータを訓練データセット (80%) とテストデータセット (20%) に分割する
#+begin_src python :session :results value
  from sklearn.model_selection import train_test_split

  X_train, X_test, y_train, y_test = train_test_split(
      X, y, test_size = 0.20, stratify = y, random_state = 1
  )
#+end_src

#+RESULTS:
** パイプラインで変換器と推定器を結合する
#+begin_src python :session :results output
  from sklearn.preprocessing import StandardScaler
  from sklearn.decomposition import PCA
  from sklearn.linear_model import LogisticRegression
  from sklearn.pipeline import make_pipeline

  # 連結する処理としてスケーリング、主成分分析、ロジスティック回帰を指定
  pipe_lr = make_pipeline(StandardScaler(),
                          PCA(n_components = 2),
                          LogisticRegression(random_state = 1, solver = "lbfgs"))
  pipe_lr.fit(X_train, y_train)
  y_pred = pipe_lr.predict(X_test)

  print("Test Accuracy: %.3f" % pipe_lr.score(X_test, y_test))
#+end_src

#+RESULTS:
: Test Accuracy: 0.956

* k分割交差検証を使ったモデルの性能の評価

** ホールドアウト法
データを訓練データセット、検証データセット、テストデータセットの3つに分割する

** k分割交差検証
非復元情報を用いて、訓練データセットをランダムにk個に分割する。
このうちのk-1個をモデルの訓練に使い、1個を性能の評価に使う。
このk個のモデルを取得し、性能を推定する。

*層化k分割交差検証*
訓練データセット全体でのクラスレベルの比率が維持される。

#+begin_src python :session :results output
  import numpy as np
  from sklearn.model_selection import StratifiedKFold
  # 分割元データ、分割数、乱数生成器の状態を指定し、
  # 層化K分割交差検証イテレータを表すStratifiedKFoldクラスのインスタンス化
  kfold = StratifiedKFold(n_splits = 10).split(X_train, y_train)
  scores = []
  # イテレータのインデックスと要素をループ処理：（上から順に）
  # データをモデルに適合
  # テストデータの正解率を算出
  # リストに正解率を追加
  # 分割の番号、0以上の要素数、正解率を出力
  for k, (train, test) in enumerate(kfold):
      pipe_lr.fit(X_train[train], y_train[train])
      score = pipe_lr.score(X_train[test], y_train[test])
      scores.append(score)
      print("Fold: %2d, Class dist.: %s, Acc: %.3f" % (k + 1, np.bincount(y_train[train]), score))

  # 正解率の平均と標準偏差を出力
  print("\nCV accuracy: %.3f +/- %.3f" % (np.mean(scores), np.std(scores)))

#+end_src

#+RESULTS:
#+begin_example
Fold:  1, Class dist.: [256 153], Acc: 0.935
Fold:  2, Class dist.: [256 153], Acc: 0.935
Fold:  3, Class dist.: [256 153], Acc: 0.957
Fold:  4, Class dist.: [256 153], Acc: 0.957
Fold:  5, Class dist.: [256 153], Acc: 0.935
Fold:  6, Class dist.: [257 153], Acc: 0.956
Fold:  7, Class dist.: [257 153], Acc: 0.978
Fold:  8, Class dist.: [257 153], Acc: 0.933
Fold:  9, Class dist.: [257 153], Acc: 0.956
Fold: 10, Class dist.: [257 153], Acc: 0.956

CV accuracy: 0.950 +/- 0.014
#+end_example

#+begin_src python :session :results output
  from sklearn.model_selection import cross_val_score
  # 交差検証のcross_val_score関数でモデルの正解率を算出
  # 推定器 estimator, 訓練データX, 予測データy, 分割数cv, CPU数n_jobsを推定
  scores = cross_val_score(estimator=pipe_lr,
                           X=X_train, y=y_train,
                           cv=10, n_jobs=1)
  print("CV accuracy scores: %s" % scores)
  print("CV accuracy: %.3f +/- %.3f" % (np.mean(scores), np.std(scores)))
#+end_src

#+RESULTS:
: CV accuracy scores: [0.93478261 0.93478261 0.95652174 0.95652174 0.93478261 0.95555556
:  0.97777778 0.93333333 0.95555556 0.95555556]
: CV accuracy: 0.950 +/- 0.014

* 学習曲線と検証曲線によるアルゴリズムの診断

** 学習曲線を使ってバイアスとバリアンスの問題を診断する
過学習の問題に対処するには、訓練データをさらに収集するか、正則化のパラメータを増やすなどして、モデルの複雑さを抑えれば良い

#+begin_src python :session :results file link
  import numpy as np
  import matplotlib.pyplot as plt
  from sklearn.preprocessing import StandardScaler
  from sklearn.linear_model import LogisticRegression
  from sklearn.pipeline import make_pipeline
  from sklearn.model_selection import learning_curve
  pipe_lr = make_pipeline(
      StandardScaler(),
      LogisticRegression(penalty = "l2", random_state = 1,
                         solver = "lbfgs", max_iter = 10000)
  )
  # learning_curve関数で交差検証による正解率を算出
  train_sizes, train_scores, test_scores = learning_curve(
      estimator = pipe_lr,
      X = X_train, y = y_train,
      train_sizes = np.linspace(0.1, 1.0, 10),
      cv = 10, n_jobs = 1
  )
  train_mean = np.mean(train_scores, axis = 1)
  train_std = np.std(train_scores, axis = 1)
  test_mean = np.mean(test_scores, axis = 1)
  test_std = np.std(test_scores, axis = 1)

  plt.close("all")

  plt.plot(
      train_sizes, train_mean,
      color = "blue", marker = "o",
      markersize = 5, label = "Training accuracy"
  )

  # fill_between関数で平均+-標準偏差の幅を塗りつぶす
  # 訓練データのサイズtrain_sizes, 透明度alpha, カラー"blue"引数に指定
  plt.fill_between(
      train_sizes,
      train_mean + train_std,
      train_mean - train_std,
      alpha = 0.15,
      color = "blue"
  )

  plt.plot(
      train_sizes, test_mean,
      color = "green", linestyle = "--", marker = "s",
      markersize = 5, label = "Validation accuracy"
  )

  plt.fill_between(
      train_sizes,
      test_mean + test_std,
      test_mean - test_std,
      alpha = 0.15,
      color = "green"
  )

  plt.grid()

  plt.xlabel("Number of training examples")
  plt.ylabel("Accuracy")
  plt.legend(loc = "lower right")
  plt.ylim([0.8, 1.03])
  plt.tight_layout()

  fname = "images/06_05.png"

  plt.savefig(fname)

  fname
#+end_src

#+RESULTS:
[[file:images/06_05.png]]

** 検証曲線を使って過学習と学習不足を明らかにする
#+begin_src python :session :results file link
  from sklearn.model_selection import validation_curve
  param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]
  # validation_curve関数によりモデルのパラメータを変化させ、交差検証による正解値を算出
  # clf__CはLogisticRegressionオブジェクトのパラメータ
  train_scores, test_scores = validation_curve(estimator=pipe_lr,
                                               X=X_train, y=y_train,
                                               param_name="logisticregression__C",
                                               param_range=param_range, cv=10)
  train_mean = np.mean(train_scores, axis = 1)
  train_std = np.std(train_scores, axis = 1)
  test_mean = np.mean(test_scores, axis = 1)
  test_std = np.std(test_scores, axis = 1)

  plt.close("all")

  plt.plot(
      param_range, train_mean,
      color = "blue", marker = "o",
      markersize = 5, label = "Training accuracy"
  )

  plt.fill_between(
      param_range,
      train_mean + train_std,
      train_mean - train_std,
      alpha = 0.15,
      color = "blue"
  )

  plt.plot(
      param_range, test_mean,
      color = "green", linestyle = "--", marker = "s",
      markersize = 5, label = "Validation accuracy"
  )

  plt.fill_between(
      param_range,
      test_mean + test_std,
      test_mean - test_std,
      alpha = 0.15,
      color = "green"
  )

  plt.grid()
  plt.xscale("log")
  plt.legend(loc="lower right")
  plt.xlabel("Parameter C")
  plt.ylabel("Accuracy")
  plt.ylim([0.8, 1.0])

  plt.tight_layout()

  fname = "images/06_06.png"

  plt.savefig(fname)

  fname
#+end_src

#+RESULTS:
[[file:images/06_06.png]]

C = 0.01 ~ 0.1あたりが最適

* グリッドサーチによる機械学習モデルのチューニング

** グリッドサーチを使ったハイパーパラメータのチューニング
#+begin_src python :session :results output
  from sklearn.model_selection import GridSearchCV
  from sklearn.svm import SVC

  pipe_svc = make_pipeline(StandardScaler(), SVC(random_state=1))
  param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]
  param_grid = [{"svc__C": param_range, "svc__kernel": ["linear"]},
                {"svc__C": param_range, "svc__gamma": param_range, "svc__kernel": ["rbf"]}]
  # ハイパーパラメータ値のリストparam_gridを指定し、
  # グリッドサーチを行うGridSearchCVクラスをインスタンス化
  gs = GridSearchCV(estimator = pipe_svc,
                    param_grid = param_grid,
                    scoring = "accuracy", cv = 10, refit = True, n_jobs = -1)
  gs = gs.fit(X_train, y_train)
  # モデルの最良スコアを出力
  print(gs.best_score_)
  # 最良スコアとなるパラメータ値を出力
  print(gs.best_params_)
#+end_src

#+RESULTS:
: 0.9846859903381642
: {'svc__C': 100.0, 'svc__gamma': 0.001, 'svc__kernel': 'rbf'}

テストデータを用いてモデル性能を評価する
#+begin_src python :session :results output
  clf = gs.best_estimator_
  # clf.fit(X_train, y_train)
  print("Test accuracy: %.3f" % clf.score(X_test, y_test))
#+end_src

#+RESULTS:
: Test accuracy: 0.974
